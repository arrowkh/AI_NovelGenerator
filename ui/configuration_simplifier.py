# ui/configuration_simplifier.py
# -*- coding: utf-8 -*-
"""
é…ç½®ç®€åŒ–å’Œæ¸è¿›å¼å­¦ä¹ ç³»ç»Ÿ
æä¾›ä¸‰å±‚é…ç½®æ¨¡å¼ï¼ˆåŸºç¡€ã€é«˜çº§ã€ä¸“å®¶ï¼‰ï¼Œè®©ç”¨æˆ·æ ¹æ®è‡ªå·±çš„æ°´å¹³é€æ­¥å­¦ä¹ å’ŒæŒæ¡ç³»ç»Ÿ
"""

import json
import os
from datetime import datetime
from enum import Enum
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict


class ConfigMode(Enum):
    """é…ç½®æ¨¡å¼æšä¸¾"""
    BASIC = "åŸºç¡€"
    ADVANCED = "é«˜çº§"
    EXPERT = "ä¸“å®¶"


class ConfigPreset(Enum):
    """é…ç½®é¢„è®¾æšä¸¾"""
    FAST = "å¿«é€Ÿ"
    BALANCED = "å¹³è¡¡"
    HIGH_QUALITY = "é«˜è´¨é‡"
    CREATIVE = "åˆ›æ„æ¨¡å¼"
    CUSTOM = "è‡ªå®šä¹‰"


@dataclass
class ConfigSnapshot:
    """é…ç½®å¿«ç…§ï¼Œç”¨äºå†å²è®°å½•"""
    timestamp: str
    mode: str
    preset: str
    config_data: Dict
    description: str
    user_satisfaction: Optional[str] = None  # "æ»¡æ„", "èƒ½æ¥å—", "ä¸æ»¡æ„"
    impact_notes: Optional[str] = None


@dataclass
class ValidationIssue:
    """é…ç½®éªŒè¯é—®é¢˜"""
    level: str  # "warning", "error", "info"
    title: str
    description: str
    suggestion: str
    auto_fix_available: bool = False
    auto_fix_data: Optional[Dict] = None


class ConfigurationSimplifier:
    """
    é…ç½®ç®€åŒ–å™¨ä¸»ç±»
    ç®¡ç†é…ç½®çš„åˆ†å±‚å±•ç¤ºã€éªŒè¯ã€å†å²è®°å½•å’Œæ™ºèƒ½å»ºè®®
    """
    
    def __init__(self, config_file: str):
        """
        åˆå§‹åŒ–é…ç½®ç®€åŒ–å™¨
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_file = config_file
        self.history_file = config_file.replace('.json', '_history.json')
        self.current_mode = ConfigMode.BASIC
        self.current_preset = ConfigPreset.BALANCED
        self.history: List[ConfigSnapshot] = []
        self._load_history()
        
    # ==================== æ¨¡å¼ç®¡ç† ====================
    
    def get_mode(self) -> ConfigMode:
        """è·å–å½“å‰é…ç½®æ¨¡å¼"""
        return self.current_mode
    
    def set_mode(self, mode: ConfigMode) -> None:
        """è®¾ç½®é…ç½®æ¨¡å¼"""
        self.current_mode = mode
        
    def get_mode_description(self, mode: ConfigMode) -> str:
        """è·å–æ¨¡å¼æè¿°"""
        descriptions = {
            ConfigMode.BASIC: "é€‚åˆæ–°æ‰‹ï¼Œåªæ˜¾ç¤ºæ ¸å¿ƒé…ç½®ï¼Œä½¿ç”¨æ¨èé¢„è®¾",
            ConfigMode.ADVANCED: "é€‚åˆä¸­çº§ç”¨æˆ·ï¼Œæ˜¾ç¤ºå¸¸ç”¨é…ç½®é¡¹ï¼Œæ”¯æŒç»†èŠ‚è°ƒæ•´",
            ConfigMode.EXPERT: "é€‚åˆé«˜çº§ç”¨æˆ·ï¼Œæ˜¾ç¤ºæ‰€æœ‰é…ç½®é¡¹ï¼Œå®Œå…¨æ§åˆ¶"
        }
        return descriptions.get(mode, "")
    
    def get_next_mode_tip(self) -> Optional[str]:
        """è·å–ä¸‹ä¸€æ¨¡å¼çš„æç¤º"""
        if self.current_mode == ConfigMode.BASIC:
            return "ğŸ’¡ æƒ³äº†è§£æ›´å¤šå—ï¼Ÿåˆ‡æ¢åˆ°é«˜çº§æ¨¡å¼æŸ¥çœ‹æ›´å¤šé…ç½®é€‰é¡¹"
        elif self.current_mode == ConfigMode.ADVANCED:
            return "ğŸ’¡ æƒ³å®Œå…¨æŒæ§å—ï¼Ÿåˆ‡æ¢åˆ°ä¸“å®¶æ¨¡å¼è·å¾—å®Œæ•´é…ç½®æƒé™"
        elif self.current_mode == ConfigMode.EXPERT:
            return "ğŸ’¡ éœ€è¦ç®€åŒ–ç•Œé¢ï¼Ÿéšæ—¶å¯ä»¥åˆ‡æ¢å›åŸºç¡€æ¨¡å¼"
        return None
    
    # ==================== é¢„è®¾ç®¡ç† ====================
    
    def get_preset_config(self, preset: ConfigPreset) -> Dict:
        """
        è·å–é¢„è®¾é…ç½®
        
        Args:
            preset: é¢„è®¾ç±»å‹
            
        Returns:
            é¢„è®¾é…ç½®å­—å…¸
        """
        presets = {
            ConfigPreset.FAST: {
                "description": "æˆæœ¬ä½ï¼Œç”Ÿæˆå¿«ï¼Œè´¨é‡è¿˜å¯ä»¥",
                "model_name": "gpt-3.5-turbo",
                "temperature": 0.7,
                "max_tokens": 4096,
                "timeout": 300,
                "estimated_time_per_chapter": "1 åˆ†é’Ÿ",
                "estimated_cost_per_chapter": "$0.02",
                "use_cases": ["å¿«é€ŸåŸå‹", "åˆç¨¿ç”Ÿæˆ", "å¤§é‡ç« èŠ‚"]
            },
            ConfigPreset.BALANCED: {
                "description": "æˆæœ¬é€‚ä¸­ï¼Œè´¨é‡å’Œé€Ÿåº¦å¹³è¡¡ï¼ˆæ¨èï¼‰",
                "model_name": "gpt-4",
                "temperature": 0.75,
                "max_tokens": 8192,
                "timeout": 600,
                "estimated_time_per_chapter": "2 åˆ†é’Ÿ",
                "estimated_cost_per_chapter": "$0.05",
                "use_cases": ["æ—¥å¸¸å†™ä½œ", "æ ‡å‡†è´¨é‡", "å¹³è¡¡æˆæœ¬"]
            },
            ConfigPreset.HIGH_QUALITY: {
                "description": "æˆæœ¬é«˜ï¼Œè´¨é‡æœ€å¥½",
                "model_name": "gpt-4-turbo",
                "temperature": 0.65,
                "max_tokens": 16384,
                "timeout": 900,
                "estimated_time_per_chapter": "3-4 åˆ†é’Ÿ",
                "estimated_cost_per_chapter": "$0.12",
                "use_cases": ["é‡è¦ç« èŠ‚", "é«˜è´¨é‡è¦æ±‚", "ä¸“ä¸šå‡ºç‰ˆ"]
            },
            ConfigPreset.CREATIVE: {
                "description": "é«˜åˆ›æ„åº¦ï¼Œé€‚åˆå¥‡å¹»/ç§‘å¹»",
                "model_name": "gpt-4",
                "temperature": 0.90,
                "max_tokens": 8192,
                "timeout": 600,
                "estimated_time_per_chapter": "2-3 åˆ†é’Ÿ",
                "estimated_cost_per_chapter": "$0.06",
                "use_cases": ["åˆ›æ„å†™ä½œ", "å¥‡å¹»å°è¯´", "ç§‘å¹»è®¾å®š"]
            }
        }
        return presets.get(preset, presets[ConfigPreset.BALANCED])
    
    def apply_preset(self, preset: ConfigPreset, current_config: Dict) -> Dict:
        """
        åº”ç”¨é¢„è®¾åˆ°å½“å‰é…ç½®
        
        Args:
            preset: é¢„è®¾ç±»å‹
            current_config: å½“å‰é…ç½®
            
        Returns:
            åº”ç”¨é¢„è®¾åçš„é…ç½®
        """
        preset_data = self.get_preset_config(preset)
        
        # æ›´æ–°ä¸»è¦é…ç½®é¡¹
        if "llm_configs" in current_config:
            for config_name, config in current_config["llm_configs"].items():
                config["temperature"] = preset_data["temperature"]
                config["max_tokens"] = preset_data["max_tokens"]
                config["timeout"] = preset_data["timeout"]
                # å¯é€‰ï¼šæ›´æ–°æ¨¡å‹åç§°ï¼ˆå¦‚æœç”¨æˆ·æƒ³è¦ï¼‰
                # config["model_name"] = preset_data["model_name"]
        
        self.current_preset = preset
        return current_config
    
    def get_preset_comparison(self) -> List[Dict]:
        """è·å–æ‰€æœ‰é¢„è®¾çš„å¯¹æ¯”ä¿¡æ¯"""
        comparison = []
        for preset in [ConfigPreset.FAST, ConfigPreset.BALANCED, 
                      ConfigPreset.HIGH_QUALITY, ConfigPreset.CREATIVE]:
            config = self.get_preset_config(preset)
            comparison.append({
                "name": preset.value,
                "description": config["description"],
                "time": config["estimated_time_per_chapter"],
                "cost": config["estimated_cost_per_chapter"],
                "use_cases": config["use_cases"]
            })
        return comparison
    
    # ==================== é…ç½®éªŒè¯ ====================
    
    def validate_config(self, config: Dict) -> List[ValidationIssue]:
        """
        éªŒè¯é…ç½®å¹¶è¿”å›é—®é¢˜åˆ—è¡¨
        
        Args:
            config: è¦éªŒè¯çš„é…ç½®
            
        Returns:
            éªŒè¯é—®é¢˜åˆ—è¡¨
        """
        issues = []
        
        # æ£€æŸ¥ LLM é…ç½®
        if "llm_configs" in config:
            for config_name, llm_config in config["llm_configs"].items():
                # æ£€æŸ¥æ¸©åº¦å€¼
                temp = llm_config.get("temperature", 0.7)
                if temp > 0.9:
                    issues.append(ValidationIssue(
                        level="warning",
                        title=f"é…ç½® '{config_name}': æ¸©åº¦å€¼è¿‡é«˜ ({temp})",
                        description="é«˜æ¸©åº¦å€¼ä¼šå¢åŠ åˆ›æ„åº¦ï¼Œä½†å¯èƒ½é™ä½ä¸€è‡´æ€§å’Œç¨³å®šæ€§",
                        suggestion="å»ºè®®ï¼šä»…åœ¨åˆ›æ„ä¼˜å…ˆçš„é¡¹ç›®ä¸­ä½¿ç”¨ï¼Œæˆ–åŒæ—¶å¯ç”¨ä¸€è‡´æ€§æ£€æŸ¥",
                        auto_fix_available=True,
                        auto_fix_data={"temperature": 0.85}
                    ))
                elif temp < 0.3:
                    issues.append(ValidationIssue(
                        level="info",
                        title=f"é…ç½® '{config_name}': æ¸©åº¦å€¼è¾ƒä½ ({temp})",
                        description="ä½æ¸©åº¦å€¼ä¼šæé«˜ä¸€è‡´æ€§ï¼Œä½†å¯èƒ½é™ä½åˆ›æ„æ€§",
                        suggestion="é€‚åˆéœ€è¦ä¸¥æ ¼æ§åˆ¶è¾“å‡ºçš„åœºæ™¯",
                        auto_fix_available=False
                    ))
                
                # æ£€æŸ¥ max_tokens
                max_tokens = llm_config.get("max_tokens", 8192)
                if max_tokens < 2000:
                    issues.append(ValidationIssue(
                        level="warning",
                        title=f"é…ç½® '{config_name}': Max Tokens è¿‡ä½ ({max_tokens})",
                        description="å¯èƒ½æ— æ³•ç”Ÿæˆè¶³å¤Ÿé•¿åº¦çš„ç« èŠ‚å†…å®¹",
                        suggestion="å»ºè®®ï¼šè‡³å°‘è®¾ç½®ä¸º 4096",
                        auto_fix_available=True,
                        auto_fix_data={"max_tokens": 4096}
                    ))
                elif max_tokens > 50000:
                    issues.append(ValidationIssue(
                        level="warning",
                        title=f"é…ç½® '{config_name}': Max Tokens è¿‡é«˜ ({max_tokens})",
                        description="å¯èƒ½å¯¼è‡´æˆæœ¬è¿‡é«˜å’Œå“åº”æ—¶é—´è¿‡é•¿",
                        suggestion="å»ºè®®ï¼šæ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´åˆ°åˆç†èŒƒå›´ï¼ˆ4096-16384ï¼‰",
                        auto_fix_available=True,
                        auto_fix_data={"max_tokens": 16384}
                    ))
                
                # æ£€æŸ¥ API Key
                api_key = llm_config.get("api_key", "")
                if not api_key or api_key.strip() == "":
                    issues.append(ValidationIssue(
                        level="error",
                        title=f"é…ç½® '{config_name}': API Key æœªè®¾ç½®",
                        description="æ²¡æœ‰ API Key å°†æ— æ³•è°ƒç”¨ LLM æœåŠ¡",
                        suggestion="è¯·åœ¨é…ç½®ä¸­å¡«å…¥æœ‰æ•ˆçš„ API Key",
                        auto_fix_available=False
                    ))
                
                # æ£€æŸ¥è¶…æ—¶è®¾ç½®
                timeout = llm_config.get("timeout", 600)
                if timeout < 60:
                    issues.append(ValidationIssue(
                        level="warning",
                        title=f"é…ç½® '{config_name}': è¶…æ—¶æ—¶é—´è¿‡çŸ­ ({timeout}ç§’)",
                        description="å¯èƒ½å¯¼è‡´è¯·æ±‚åœ¨å®Œæˆå‰è¶…æ—¶",
                        suggestion="å»ºè®®ï¼šè‡³å°‘è®¾ç½®ä¸º 300 ç§’",
                        auto_fix_available=True,
                        auto_fix_data={"timeout": 300}
                    ))
        
        # æ£€æŸ¥åµŒå…¥é…ç½®
        if "embedding_configs" in config:
            for emb_name, emb_config in config["embedding_configs"].items():
                api_key = emb_config.get("api_key", "")
                if not api_key or api_key.strip() == "":
                    issues.append(ValidationIssue(
                        level="error",
                        title=f"Embeddingé…ç½® '{emb_name}': API Key æœªè®¾ç½®",
                        description="æ²¡æœ‰ API Key å°†æ— æ³•ä½¿ç”¨å‘é‡æ£€ç´¢åŠŸèƒ½",
                        suggestion="è¯·åœ¨é…ç½®ä¸­å¡«å…¥æœ‰æ•ˆçš„ API Key",
                        auto_fix_available=False
                    ))
        
        # æ£€æŸ¥é…ç½®å†²çª
        issues.extend(self._check_config_conflicts(config))
        
        return issues
    
    def _check_config_conflicts(self, config: Dict) -> List[ValidationIssue]:
        """æ£€æŸ¥é…ç½®å†²çª"""
        conflicts = []
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„å†²çªæ£€æŸ¥é€»è¾‘
        # ä¾‹å¦‚ï¼šæ£€æŸ¥å¹¶è¡Œåº¦ä¸ API é€Ÿç‡é™åˆ¶çš„å†²çª
        
        return conflicts
    
    def auto_fix_issue(self, issue: ValidationIssue, config: Dict, 
                       config_name: str) -> Dict:
        """
        è‡ªåŠ¨ä¿®å¤é…ç½®é—®é¢˜
        
        Args:
            issue: éªŒè¯é—®é¢˜
            config: é…ç½®å­—å…¸
            config_name: é…ç½®åç§°
            
        Returns:
            ä¿®å¤åçš„é…ç½®
        """
        if not issue.auto_fix_available or not issue.auto_fix_data:
            return config
        
        if config_name in config.get("llm_configs", {}):
            config["llm_configs"][config_name].update(issue.auto_fix_data)
        
        return config
    
    # ==================== æ™ºèƒ½å»ºè®® ====================
    
    def get_parameter_impact(self, param_name: str, 
                            old_value: Any, new_value: Any) -> Dict:
        """
        è·å–å‚æ•°å˜æ›´çš„å½±å“åˆ†æ
        
        Args:
            param_name: å‚æ•°åç§°
            old_value: æ—§å€¼
            new_value: æ–°å€¼
            
        Returns:
            å½±å“åˆ†æå­—å…¸
        """
        impact = {
            "parameter": param_name,
            "old_value": old_value,
            "new_value": new_value,
            "changes": []
        }
        
        if param_name == "temperature":
            if new_value > old_value:
                impact["changes"] = [
                    {"aspect": "åˆ›æ„åº¦", "change": "â†‘â†‘" if new_value - old_value > 0.2 else "â†‘"},
                    {"aspect": "ä¸€è‡´æ€§", "change": "â†“â†“" if new_value - old_value > 0.2 else "â†“"},
                    {"aspect": "é¢„è®¡æˆæœ¬", "change": "â†’" if abs(new_value - old_value) < 0.1 else "â†‘"},
                ]
            else:
                impact["changes"] = [
                    {"aspect": "åˆ›æ„åº¦", "change": "â†“â†“" if old_value - new_value > 0.2 else "â†“"},
                    {"aspect": "ä¸€è‡´æ€§", "change": "â†‘â†‘" if old_value - new_value > 0.2 else "â†‘"},
                    {"aspect": "é¢„è®¡æˆæœ¬", "change": "â†’"},
                ]
            
            # æ·»åŠ å»ºè®®
            if new_value > 0.9:
                impact["warning"] = "âš ï¸ è­¦å‘Š: è¿™ä¸ªæ¸©åº¦å€¼å¾ˆé«˜ï¼"
                impact["recommendations"] = [
                    "ä»…åœ¨'åˆ›æ„ä¼˜å…ˆ'çš„é¡¹ç›®ä¸­ä½¿ç”¨",
                    "åŒæ—¶å¯ç”¨'ä¸€è‡´æ€§æ£€æŸ¥'æ¥å¼¥è¡¥",
                    "è€ƒè™‘ä½¿ç”¨åˆ›æ„æ¨¡å¼é¢„è®¾"
                ]
            elif new_value < 0.3:
                impact["info"] = "â„¹ï¸ æç¤º: è¿™ä¸ªæ¸©åº¦å€¼å¾ˆä½"
                impact["recommendations"] = [
                    "é€‚åˆéœ€è¦ä¸¥æ ¼ä¸€è‡´æ€§çš„é¡¹ç›®",
                    "è¾“å‡ºä¼šæ›´åŠ ä¿å®ˆå’Œå¯é¢„æµ‹"
                ]
        
        elif param_name == "max_tokens":
            token_change_pct = ((new_value - old_value) / old_value) * 100
            if new_value > old_value:
                impact["changes"] = [
                    {"aspect": "ç« èŠ‚é•¿åº¦", "change": f"â†‘ (çº¦{token_change_pct:.0f}%)"},
                    {"aspect": "ç”Ÿæˆæ—¶é—´", "change": "â†‘"},
                    {"aspect": "æˆæœ¬", "change": f"â†‘ (çº¦{token_change_pct:.0f}%)"},
                ]
            else:
                impact["changes"] = [
                    {"aspect": "ç« èŠ‚é•¿åº¦", "change": f"â†“ (çº¦{abs(token_change_pct):.0f}%)"},
                    {"aspect": "ç”Ÿæˆæ—¶é—´", "change": "â†“"},
                    {"aspect": "æˆæœ¬", "change": f"â†“ (çº¦{abs(token_change_pct):.0f}%)"},
                ]
        
        elif param_name == "timeout":
            if new_value < 300:
                impact["warning"] = "âš ï¸ è­¦å‘Š: è¶…æ—¶æ—¶é—´å¯èƒ½è¿‡çŸ­"
                impact["recommendations"] = [
                    "å¯èƒ½å¯¼è‡´é•¿ç« èŠ‚ç”Ÿæˆè¢«ä¸­æ–­",
                    "å»ºè®®è‡³å°‘è®¾ç½®ä¸º 300 ç§’"
                ]
        
        return impact
    
    # ==================== å†å²è®°å½• ====================
    
    def _load_history(self) -> None:
        """ä»æ–‡ä»¶åŠ è½½å†å²è®°å½•"""
        if os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.history = [
                        ConfigSnapshot(**item) for item in data
                    ]
            except Exception as e:
                print(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
                self.history = []
        else:
            self.history = []
    
    def _save_history(self) -> None:
        """ä¿å­˜å†å²è®°å½•åˆ°æ–‡ä»¶"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(
                    [asdict(snapshot) for snapshot in self.history],
                    f, ensure_ascii=False, indent=2
                )
        except Exception as e:
            print(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")
    
    def add_history_snapshot(self, config_data: Dict, 
                            description: str) -> None:
        """
        æ·»åŠ é…ç½®å¿«ç…§åˆ°å†å²è®°å½•
        
        Args:
            config_data: é…ç½®æ•°æ®
            description: å˜æ›´æè¿°
        """
        snapshot = ConfigSnapshot(
            timestamp=datetime.now().isoformat(),
            mode=self.current_mode.value,
            preset=self.current_preset.value,
            config_data=config_data.copy(),
            description=description
        )
        self.history.append(snapshot)
        
        # åªä¿ç•™æœ€è¿‘ 50 æ¡è®°å½•
        if len(self.history) > 50:
            self.history = self.history[-50:]
        
        self._save_history()
    
    def get_history(self, limit: int = 10) -> List[ConfigSnapshot]:
        """
        è·å–å†å²è®°å½•
        
        Args:
            limit: è¿”å›çš„æœ€å¤§è®°å½•æ•°
            
        Returns:
            å†å²è®°å½•åˆ—è¡¨
        """
        return self.history[-limit:][::-1]  # è¿”å›æœ€è¿‘çš„è®°å½•ï¼Œå€’åº
    
    def restore_from_history(self, timestamp: str) -> Optional[Dict]:
        """
        ä»å†å²è®°å½•æ¢å¤é…ç½®
        
        Args:
            timestamp: æ—¶é—´æˆ³
            
        Returns:
            é…ç½®æ•°æ®ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å› None
        """
        for snapshot in self.history:
            if snapshot.timestamp == timestamp:
                return snapshot.config_data.copy()
        return None
    
    def update_snapshot_satisfaction(self, timestamp: str, 
                                    satisfaction: str, 
                                    impact_notes: str = "") -> None:
        """
        æ›´æ–°å†å²å¿«ç…§çš„æ»¡æ„åº¦åé¦ˆ
        
        Args:
            timestamp: æ—¶é—´æˆ³
            satisfaction: æ»¡æ„åº¦ï¼ˆ"æ»¡æ„", "èƒ½æ¥å—", "ä¸æ»¡æ„"ï¼‰
            impact_notes: å½±å“è¯´æ˜
        """
        for snapshot in self.history:
            if snapshot.timestamp == timestamp:
                snapshot.user_satisfaction = satisfaction
                snapshot.impact_notes = impact_notes
                self._save_history()
                break
    
    # ==================== é…ç½®å¯¼å…¥å¯¼å‡º ====================
    
    def export_config(self, config: Dict, export_path: str) -> bool:
        """
        å¯¼å‡ºé…ç½®åˆ°æ–‡ä»¶
        
        Args:
            config: é…ç½®æ•°æ®
            export_path: å¯¼å‡ºè·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            export_data = {
                "version": "1.0",
                "exported_at": datetime.now().isoformat(),
                "mode": self.current_mode.value,
                "preset": self.current_preset.value,
                "config": config
            }
            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"å¯¼å‡ºé…ç½®å¤±è´¥: {e}")
            return False
    
    def import_config(self, import_path: str) -> Optional[Dict]:
        """
        ä»æ–‡ä»¶å¯¼å…¥é…ç½®
        
        Args:
            import_path: å¯¼å…¥è·¯å¾„
            
        Returns:
            é…ç½®æ•°æ®ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            with open(import_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if "config" in data:
                    return data["config"]
                return data  # å…¼å®¹æ—§æ ¼å¼
        except Exception as e:
            print(f"å¯¼å…¥é…ç½®å¤±è´¥: {e}")
            return None
    
    # ==================== UI è¾…åŠ©æ–¹æ³• ====================
    
    def get_visible_fields(self, mode: ConfigMode) -> Dict[str, List[str]]:
        """
        è·å–ä¸åŒæ¨¡å¼ä¸‹åº”è¯¥æ˜¾ç¤ºçš„å­—æ®µ
        
        Args:
            mode: é…ç½®æ¨¡å¼
            
        Returns:
            å­—æ®µåˆ†ç»„å­—å…¸
        """
        if mode == ConfigMode.BASIC:
            return {
                "llm": ["preset_selector", "temperature"],
                "generation": ["estimated_info"],
                "actions": ["save", "reset"]
            }
        elif mode == ConfigMode.ADVANCED:
            return {
                "llm": ["model_name", "api_key", "base_url", "max_tokens", 
                       "temperature", "top_p"],
                "optimization": ["consistency_check", "style_check", 
                               "quality_score", "auto_fix"],
                "performance": ["parallel_generation", "vector_cache"],
                "actions": ["save", "reset", "test"]
            }
        else:  # EXPERT
            return {
                "llm": ["all"],
                "embedding": ["all"],
                "generation": ["all"],
                "optimization": ["all"],
                "performance": ["all"],
                "advanced": ["all"],
                "actions": ["save", "reset", "test", "import", "export", "validate"]
            }
    
    def get_field_tooltip(self, field_name: str, mode: ConfigMode) -> str:
        """
        è·å–å­—æ®µçš„å·¥å…·æç¤ºï¼ˆæ ¹æ®æ¨¡å¼è°ƒæ•´è¯¦ç»†ç¨‹åº¦ï¼‰
        
        Args:
            field_name: å­—æ®µåç§°
            mode: é…ç½®æ¨¡å¼
            
        Returns:
            å·¥å…·æç¤ºæ–‡æœ¬
        """
        tooltips = {
            "temperature": {
                ConfigMode.BASIC: "æ§åˆ¶åˆ›æ„åº¦ï¼šä½å€¼æ›´ä¿å®ˆï¼Œé«˜å€¼æ›´æœ‰åˆ›æ„",
                ConfigMode.ADVANCED: "Temperature (0.0-2.0): æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ã€‚è¾ƒä½çš„å€¼ä½¿è¾“å‡ºæ›´ç¡®å®šï¼Œè¾ƒé«˜çš„å€¼ä½¿è¾“å‡ºæ›´å¤šæ ·åŒ–",
                ConfigMode.EXPERT: "Temperature å‚æ•°æ§åˆ¶ softmax å‡½æ•°çš„æ¸©åº¦ï¼Œå½±å“ token é€‰æ‹©çš„æ¦‚ç‡åˆ†å¸ƒã€‚èŒƒå›´ 0.0-2.0ï¼Œæ¨è 0.7-0.9"
            },
            "max_tokens": {
                ConfigMode.BASIC: "æ§åˆ¶ç”Ÿæˆå†…å®¹çš„æœ€å¤§é•¿åº¦",
                ConfigMode.ADVANCED: "Max Tokens: é™åˆ¶å•æ¬¡ç”Ÿæˆçš„æœ€å¤§ token æ•°é‡ï¼Œå½±å“ç« èŠ‚é•¿åº¦å’Œæˆæœ¬",
                ConfigMode.EXPERT: "Max Tokens: API è°ƒç”¨çš„ token ä¸Šé™ã€‚æ³¨æ„ï¼šå®é™…æ¶ˆè€— = prompt tokens + completion tokens"
            }
        }
        
        field_tooltips = tooltips.get(field_name, {})
        return field_tooltips.get(mode, "")
    
    def should_show_field(self, field_name: str, group: str, 
                         mode: ConfigMode) -> bool:
        """
        åˆ¤æ–­æŸä¸ªå­—æ®µåœ¨å½“å‰æ¨¡å¼ä¸‹æ˜¯å¦åº”è¯¥æ˜¾ç¤º
        
        Args:
            field_name: å­—æ®µåç§°
            group: å­—æ®µåˆ†ç»„
            mode: é…ç½®æ¨¡å¼
            
        Returns:
            æ˜¯å¦æ˜¾ç¤º
        """
        visible_fields = self.get_visible_fields(mode)
        
        if group not in visible_fields:
            return False
        
        fields = visible_fields[group]
        
        # å¦‚æœæ˜¯ "all"ï¼Œæ˜¾ç¤ºæ‰€æœ‰å­—æ®µ
        if "all" in fields:
            return True
        
        return field_name in fields
    
    # ==================== å­¦ä¹ è·¯å¾„ ====================
    
    def get_learning_resources(self, field_name: str) -> Dict:
        """
        è·å–å­—æ®µçš„å­¦ä¹ èµ„æº
        
        Args:
            field_name: å­—æ®µåç§°
            
        Returns:
            å­¦ä¹ èµ„æºå­—å…¸
        """
        resources = {
            "temperature": {
                "quick_tutorial": "Temperature æ˜¯ä»€ä¹ˆï¼Ÿ\n\nå®ƒæ§åˆ¶ AI çš„åˆ›æ„ç¨‹åº¦ã€‚æƒ³è±¡ä¸€ä¸‹å†™ä½œæ—¶çš„çµæ„ŸçŠ¶æ€ï¼š\nâ€¢ ä½æ¸©åº¦(0.3)ï¼šåƒä¸¥è°¨çš„æŠ€æœ¯å†™ä½œï¼Œæ¯ä¸ªè¯éƒ½å¾ˆç¡®å®š\nâ€¢ ä¸­æ¸©åº¦(0.7)ï¼šåƒæ­£å¸¸çš„åˆ›ä½œï¼Œæ—¢æœ‰é€»è¾‘åˆæœ‰åˆ›æ„\nâ€¢ é«˜æ¸©åº¦(1.2+)ï¼šåƒå¤´è„‘é£æš´ï¼Œå……æ»¡æƒŠå–œä½†å¯èƒ½ä¸å¤ªè¿è´¯",
                "advanced_guide": "å¦‚ä½•æ ¹æ®é¡¹ç›®é€‰æ‹©æ¸©åº¦ï¼Ÿ\n\nâ€¢ æŠ€æœ¯æ–‡æ¡£ã€å†å²å°è¯´ï¼š0.5-0.7ï¼ˆéœ€è¦å‡†ç¡®æ€§ï¼‰\nâ€¢ ç°ä»£å°è¯´ã€ä¼ è®°ï¼š0.7-0.8ï¼ˆå¹³è¡¡ï¼‰\nâ€¢ ç§‘å¹»ã€å¥‡å¹»ï¼š0.8-1.0ï¼ˆéœ€è¦æƒ³è±¡åŠ›ï¼‰\nâ€¢ å®éªŒæ€§åˆ›ä½œï¼š1.0+ï¼ˆè¿½æ±‚ç‹¬ç‰¹æ€§ï¼‰",
                "video_url": "https://example.com/temperature-tutorial",
                "community_discussions": "https://example.com/community/temperature"
            },
            "max_tokens": {
                "quick_tutorial": "Max Tokens æ§åˆ¶ç”Ÿæˆé•¿åº¦\n\n1 token â‰ˆ 0.75 ä¸ªè‹±æ–‡å•è¯ â‰ˆ 1-2 ä¸ªä¸­æ–‡å­—ç¬¦\n\nå¸¸è§è®¾ç½®ï¼š\nâ€¢ çŸ­ç« èŠ‚ï¼ˆ1000å­—ï¼‰ï¼š2000-3000 tokens\nâ€¢ ä¸­ç­‰ç« èŠ‚ï¼ˆ3000å­—ï¼‰ï¼š6000-8000 tokens\nâ€¢ é•¿ç« èŠ‚ï¼ˆ5000å­—+ï¼‰ï¼š10000+ tokens",
                "advanced_guide": "ä¼˜åŒ– Token ä½¿ç”¨ï¼š\n\nâ€¢ é¢„ç•™ 20-30% ç»™ promptï¼ˆç³»ç»Ÿæç¤ºã€ä¸Šä¸‹æ–‡ç­‰ï¼‰\nâ€¢ ç›‘æ§å®é™…ä½¿ç”¨é‡ï¼Œé¿å…æµªè´¹\nâ€¢ è€ƒè™‘æˆæœ¬ï¼štokens è¶Šå¤šï¼Œæˆæœ¬è¶Šé«˜",
            }
        }
        return resources.get(field_name, {})
    
    def get_usage_statistics(self) -> Dict:
        """
        è·å–ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.history:
            return {
                "total_configs": 0,
                "most_used_preset": "æ— ",
                "most_used_mode": "æ— "
            }
        
        # ç»Ÿè®¡æœ€å¸¸ç”¨çš„é¢„è®¾
        preset_counts = {}
        mode_counts = {}
        
        for snapshot in self.history:
            preset_counts[snapshot.preset] = preset_counts.get(snapshot.preset, 0) + 1
            mode_counts[snapshot.mode] = mode_counts.get(snapshot.mode, 0) + 1
        
        most_used_preset = max(preset_counts.items(), key=lambda x: x[1])[0] if preset_counts else "æ— "
        most_used_mode = max(mode_counts.items(), key=lambda x: x[1])[0] if mode_counts else "æ— "
        
        # è®¡ç®—æ»¡æ„åº¦
        satisfaction_counts = {
            "æ»¡æ„": 0,
            "èƒ½æ¥å—": 0,
            "ä¸æ»¡æ„": 0
        }
        
        for snapshot in self.history:
            if snapshot.user_satisfaction:
                satisfaction_counts[snapshot.user_satisfaction] = \
                    satisfaction_counts.get(snapshot.user_satisfaction, 0) + 1
        
        return {
            "total_configs": len(self.history),
            "most_used_preset": most_used_preset,
            "most_used_mode": most_used_mode,
            "satisfaction_stats": satisfaction_counts
        }


# ==================== å…¨å±€å·¥å…·å‡½æ•° ====================

def format_time_ago(timestamp_str: str) -> str:
    """
    æ ¼å¼åŒ–æ—¶é—´ä¸ºç›¸å¯¹æ—¶é—´ï¼ˆä¾‹å¦‚ï¼š2å°æ—¶å‰ï¼‰
    
    Args:
        timestamp_str: ISO æ ¼å¼çš„æ—¶é—´å­—ç¬¦ä¸²
        
    Returns:
        ç›¸å¯¹æ—¶é—´å­—ç¬¦ä¸²
    """
    try:
        timestamp = datetime.fromisoformat(timestamp_str)
        now = datetime.now()
        delta = now - timestamp
        
        if delta.days > 0:
            return f"{delta.days} å¤©å‰"
        elif delta.seconds >= 3600:
            return f"{delta.seconds // 3600} å°æ—¶å‰"
        elif delta.seconds >= 60:
            return f"{delta.seconds // 60} åˆ†é’Ÿå‰"
        else:
            return "åˆšåˆš"
    except:
        return timestamp_str


def estimate_cost_and_time(config: Dict) -> Tuple[str, str]:
    """
    ä¼°ç®—é…ç½®çš„æˆæœ¬å’Œæ—¶é—´
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        (é¢„è®¡æˆæœ¬, é¢„è®¡æ—¶é—´) å…ƒç»„
    """
    # è¿™é‡Œå¯ä»¥æ ¹æ®æ¨¡å‹å’Œ token æ•°é‡è¿›è¡Œæ›´ç²¾ç¡®çš„ä¼°ç®—
    # ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäº max_tokens
    
    if "llm_configs" not in config:
        return ("æœªçŸ¥", "æœªçŸ¥")
    
    # å–ç¬¬ä¸€ä¸ªé…ç½®è¿›è¡Œä¼°ç®—
    first_config = list(config["llm_configs"].values())[0]
    max_tokens = first_config.get("max_tokens", 8192)
    model_name = first_config.get("model_name", "").lower()
    
    # ç®€å•çš„æˆæœ¬ä¼°ç®—ï¼ˆè¿™äº›æ˜¯ç¤ºä¾‹å€¼ï¼Œå®é™…åº”æ ¹æ® API å®šä»·è°ƒæ•´ï¼‰
    if "gpt-4" in model_name:
        cost_per_1k = 0.03
        time_factor = 3
    elif "gpt-3.5" in model_name:
        cost_per_1k = 0.002
        time_factor = 1
    else:
        cost_per_1k = 0.01
        time_factor = 2
    
    estimated_cost = (max_tokens / 1000) * cost_per_1k
    estimated_time = (max_tokens / 1000) * time_factor
    
    return (f"${estimated_cost:.2f}", f"{estimated_time:.1f} åˆ†é’Ÿ")
